{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXxw9SMEXzDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d8168b-e045-41b4-eb62-73df3811df14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers peft torch bitsandbytes accelerate huggingface_hub trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkXHk4Hor-2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97cd0e1-eb0e-4af5-9711-b47063f1ae72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `All App` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `All App`\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('hf_token')\n",
        "!huggingface-cli login --token {hf_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znjgiO4AXtoC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ab60c7cea29d462aa75bb730ce11f750",
            "eb6ee71b97e642558f7f6903d335285b",
            "21039639d149416db4741b3cd54b7f27",
            "2d328342e6664f7ca0ef31420bce4911",
            "f18a1bbb76b049c2a1aa3e02be684369",
            "d3709d0c8e4241f89b9f411cfbe350e0",
            "3e51d8a214ea4d9cac422c0b947042b0",
            "962dd6e798c74355a092724b971b73f2",
            "57a7b7dc6d4f49038c74b1ddf1050ee9",
            "5c57afe3f6a642efa2ac25487f94501f",
            "02d84bf01bd84b299cca24b1c7b5dc41"
          ]
        },
        "outputId": "fe0b8687-c2f4-4634-a797-7b942e942892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   100%|          | 8/8 [00:06<00:00, 1.28it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab60c7cea29d462aa75bb730ce11f750"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import torch\n",
        "\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=getattr(torch, \"float16\"), bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant= False),\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfFehrEfiKRF"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
        "model.config.pretraining_tp = 1\n",
        "#model.gradient_checkpointing_enable()\n",
        "model.gradient_checkpointing_disable()\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.add_bos_token, tokenizer.add_eos_token\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_steps=500,                # Guardar modelo cada 100 pasos, menos frecuente para grandes lotes\n",
        "    logging_steps=50,              # Mostrar logs cada 50 pasos\n",
        "    eval_strategy=\"steps\",         # Evaluar cada ciertos pasos\n",
        "    per_device_train_batch_size=8, # Tamaño de batch mayor para aprovechar GPU\n",
        "    gradient_accumulation_steps=1, # Ajustado para un batch efectivo razonable\n",
        "    learning_rate=2e-5,            # Tasa de aprendizaje más baja para mayor estabilidad\n",
        "    weight_decay=0.01,             # Regularización más fuerte para modelos grandes\n",
        "    optim=\"paged_adamw_32bit\",     # Optimizador eficiente en GPU\n",
        "    num_train_epochs=2,            # Incrementa épocas para un ajuste fino más completo\n",
        "    save_total_limit=3,            # Mantén hasta 3 checkpoints\n",
        "    fp16=False,                    # Habilita precisión mixta compatible con T4\n",
        "    bf16=True,                     # No necesario en T4\n",
        "    max_grad_norm=1.0,             # Límite mayor para gradientes más estables\n",
        "    max_steps=-1,                  # Ignorado, controlado por num_train_epochs\n",
        "    warmup_ratio=0.1,              # Warmup más largo para mayor estabilidad inicial\n",
        "    group_by_length=True,          # Mantén agrupación por longitud para eficiencia en memoria\n",
        "    lr_scheduler_type=\"linear\",    # Cambia a \"linear\" para decaimiento suave del learning rate\n",
        "    report_to=\"wandb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E00dMBoM-BLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a758c7e2-358f-42ed-dcae-86abc0e20019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de entrenamiento: 2859 muestras\n",
            "Conjunto de evaluación: 505 muestras\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset, load_dataset, concatenate_datasets\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Función para formatear un dataset general\n",
        "def format_general_dataset(sample):\n",
        "    \"\"\"Preserva la estructura del dataset sin agregar redundancias.\"\"\"\n",
        "    try:\n",
        "        system_prompt = sample[\"<|system|>\"]\n",
        "        user_prompt = sample[\"<|user|>\"]\n",
        "        assistant_response = sample[\"<|assistant|>\"]\n",
        "\n",
        "        # Reestructurar para una clave unificada sin alterar el contenido\n",
        "        sample[\"text\"] = f\"<|system|>: {system_prompt}\\n<|user|>: {user_prompt}\\n<|assistant|>: {assistant_response}\"\n",
        "    except KeyError as e:\n",
        "        raise ValueError(f\"Falta una clave requerida en el dataset: {e}\")\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Función para formatear un dataset de recomendaciones\n",
        "def format_recommendations_dataset(sample):\n",
        "    \"\"\"Formatea el dataset inicial de recomendaciones.\"\"\"\n",
        "    try:\n",
        "        system_prompt = sample[\"<|system|>\"]\n",
        "        user_data = json.loads(sample[\"<|user|>\"])[\"user_profile\"]\n",
        "        assistant_response = sample[\"<|assistant|>\"]\n",
        "\n",
        "        # Formatear el perfil del usuario en texto claro\n",
        "        user_profile = (\n",
        "            f\"User Profile:\\n\"\n",
        "            f\"- Age: {user_data.get('edad')}\\n\"\n",
        "            f\"- Monthly Income: {user_data.get('ingresos_mensuales')}\\n\"\n",
        "            f\"- Monthly Savings: {user_data.get('ahorro_mensual')}\\n\"\n",
        "            f\"- Risk Tolerance: {user_data.get('tolerancia_riesgo')}\\n\"\n",
        "            f\"- Investment Horizon: {user_data.get('horizonte_inversion')}\\n\"\n",
        "            f\"- Financial Goal: {user_data.get('objetivo_financiero')}\\n\"\n",
        "        )\n",
        "\n",
        "        # Generar texto formateado para el modelo\n",
        "        sample[\"text\"] = f\"<|system|>: {system_prompt}\\n<|user|>: {user_profile}\\n<|assistant|>: {assistant_response}\"\n",
        "    except (KeyError, json.JSONDecodeError) as e:\n",
        "        raise ValueError(f\"Error al procesar el dataset `recomendaciones_iniciales`: {e}\")\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Definición de archivos de datasets\n",
        "datasets = {\n",
        "    \"comparaciones_esquematico\": os.path.join(\"q&a_comparaciones_esquematico.jsonl\"),\n",
        "    \"recomendaciones_iniciales\": os.path.join(\"recomendaciones_iniciales.jsonl\"),\n",
        "    \"comparaciones_conversacionales\": os.path.join(\"q&a_comparaciones_conversacionales.jsonl\"),\n",
        "    \"conceptos_inversiones\": os.path.join(\"conceptos_inversiones_Q&A.jsonl\")\n",
        "}\n",
        "\n",
        "# Procesar datasets con el formateo correspondiente\n",
        "processed_datasets = {}\n",
        "for name, path in datasets.items():\n",
        "    dataset = load_dataset(\"json\", data_files=path)[\"train\"]\n",
        "    if name == \"recomendaciones_iniciales\":\n",
        "        formatted_dataset = dataset.map(format_recommendations_dataset, remove_columns=[\"<|system|>\", \"<|user|>\", \"<|assistant|>\"])\n",
        "    else:\n",
        "        formatted_dataset = dataset.map(format_general_dataset, remove_columns=[\"<|system|>\", \"<|user|>\", \"<|assistant|>\"])\n",
        "\n",
        "    processed_datasets[name] = formatted_dataset\n",
        "\n",
        "# Combinar datasets\n",
        "combined_dataset = concatenate_datasets([processed_datasets[name] for name in processed_datasets])\n",
        "\n",
        "# Dividir en entrenamiento y evaluación\n",
        "final_dataset = combined_dataset.train_test_split(test_size=0.15, seed=42)\n",
        "train_dataset = final_dataset[\"train\"]\n",
        "eval_dataset = final_dataset[\"test\"]\n",
        "\n",
        "# Data Collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # False porque es un modelo causal, no de modelado de lenguaje enmascarado\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de entrenamiento: {len(train_dataset)} muestras\")\n",
        "print(f\"Conjunto de evaluación: {len(eval_dataset)} muestras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3BRI3L9dqXM"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from accelerate import Accelerator\n",
        "\n",
        "trainer = SFTTrainer(model = model,\n",
        "                    args = training_args,\n",
        "                    train_dataset = train_dataset,\n",
        "                    eval_dataset = eval_dataset,\n",
        "                    peft_config=lora_config,\n",
        "                    processing_class = tokenizer,\n",
        "                    data_collator=data_collator,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di_AikToI-QT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f3cbd1e2-f739-4324-b332-bdb114c060dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mebayego\u001b[0m (\u001b[33mebayego-universitat-oberta-de-catalunya\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241221_153508-wa75hk1c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B/runs/wa75hk1c' target=\"_blank\">lyric-durian-7</a></strong> to <a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B' target=\"_blank\">https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B/runs/wa75hk1c' target=\"_blank\">https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B/runs/wa75hk1c</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import wandb\n",
        "wandb_token = userdata.get('wandb_token')\n",
        "wandb.login(key = wandb_token)\n",
        "run = wandb.init(\n",
        "    project='Fine tuning Zephyr 7B',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MuPjujHGptJl",
        "outputId": "7e64582a-226f-467f-b0c4-9751363f1ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='716' max='716' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [716/716 39:45, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.635000</td>\n",
              "      <td>1.496082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.286700</td>\n",
              "      <td>0.987415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.734800</td>\n",
              "      <td>0.517745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.424300</td>\n",
              "      <td>0.370512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.312300</td>\n",
              "      <td>0.276465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.239283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.231300</td>\n",
              "      <td>0.216503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.200281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.182800</td>\n",
              "      <td>0.193877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.190400</td>\n",
              "      <td>0.186046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>0.184386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.164400</td>\n",
              "      <td>0.181378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>0.178891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.176300</td>\n",
              "      <td>0.178946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=716, training_loss=0.43346010439888727, metrics={'train_runtime': 2388.8506, 'train_samples_per_second': 2.394, 'train_steps_per_second': 0.3, 'total_flos': 1.9163662773178368e+17, 'train_loss': 0.43346010439888727, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "344c0d5411604acdb9c97b06efb0ffae",
            "b3b9d9c3a8b84ae29032f8245041fdb6",
            "8247dada9c4a46b59dc7da9a34ef2261",
            "c97eccca84d941648870bc0e4044e7da",
            "bc3917063ce9468aa4adc34f5f0a02fd",
            "f71b86daf3c640588fdb0e05a789cab7",
            "fd556626f812485e9b986236bc303e0f",
            "5f015bc8e46343f3ab99878210048b18",
            "f91942b04ef2457989c583ee99bccdea",
            "853aa6e74e5a491c8b7d612c100ec88d",
            "412eba01a7fd406b9b42247fbd2cde40"
          ]
        },
        "id": "1yw567qxrlst",
        "outputId": "9f16d5dc-f04f-462b-fe20-87615bb1407d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▇▃▃▆▇▇█▄▇▁▄▄▅</td></tr><tr><td>eval/samples_per_second</td><td>▃▂▆▆▃▂▂▁▅▂█▅▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▃▂▆▆▂▂▂▁▅▂█▅▅▄</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▄▄▅▄▄▄█▁▂▂▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▆█▇▇▆▆▅▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.17895</td></tr><tr><td>eval/runtime</td><td>47.5255</td></tr><tr><td>eval/samples_per_second</td><td>10.626</td></tr><tr><td>eval/steps_per_second</td><td>1.347</td></tr><tr><td>total_flos</td><td>1.9163662773178368e+17</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>716</td></tr><tr><td>train/grad_norm</td><td>1.32777</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1763</td></tr><tr><td>train_loss</td><td>0.43346</td></tr><tr><td>train_runtime</td><td>2388.8506</td></tr><tr><td>train_samples_per_second</td><td>2.394</td></tr><tr><td>train_steps_per_second</td><td>0.3</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lyric-durian-7</strong> at: <a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B/runs/wa75hk1c' target=\"_blank\">https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B/runs/wa75hk1c</a><br> View project at: <a href='https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B' target=\"_blank\">https://wandb.ai/ebayego-universitat-oberta-de-catalunya/Fine%20tuning%20Zephyr%207B</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241221_153508-wa75hk1c/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "344c0d5411604acdb9c97b06efb0ffae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning completado. Modelo y tokenizador guardados en './final_model'.\n"
          ]
        }
      ],
      "source": [
        "new_model = \"TFG\"\n",
        "trainer.model.save_pretrained(new_model)\n",
        "wandb.finish()\n",
        "\n",
        "trainer.model.push_to_hub(new_model, use_temp_dir=False)\n",
        "\n",
        "print(\"Fine-tuning completado. Modelo y tokenizador guardados en './final_model'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbSDoNntBfwn",
        "outputId": "e7b1a73a-e084-45d5-f96b-e472e5169dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo completo guardado en './final_full_model'.\n"
          ]
        }
      ],
      "source": [
        "model = model.merge_and_unload()\n",
        "\n",
        "# Guardar el modelo completo\n",
        "output_dir = \"./final_full_model\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Modelo completo guardado en '{output_dir}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUYezZhCfEIW",
        "outputId": "9431f196-3853-4425-8723-1522d2fc7283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=1000,  # Límite máximo razonable\n",
        "    min_length=50,   # Longitud mínima para evitar respuestas truncadas\n",
        "    temperature=0.9, # Control de aleatoriedad\n",
        "    top_p=0.95,      # Diversidad de respuestas\n",
        "    eos_token_id=tokenizer.eos_token_id  # Detenerse al encontrar <eos>\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFve0QRW-NaD",
        "outputId": "575166ac-093a-46da-99e2-d2857e59ecaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las ETFs (Exchange Traded Funds) se pueden clasificar en dos tipos principales: ETFs de acumulación y ETFs de distribución. La principal diferencia entre ambos es cómo se distribuyen los ingresos y los gastos entre los accionistas.\n",
            "\n",
            "En los ETFs de acumulación, los ingresos y los gastos se acumulan en la cartera de la ETF, y se distribuyen a los accionistas en forma de capital de distribución al final del año fiscal. Esto significa que los accionistas pueden optar por reinvertir los ingresos en la ETF o retirirlos en forma de dividendos. Los ETFs de acumulación pueden ser atractivos para los inversores que buscan un rendimiento más estable y predictible, ya que los ingresos se acumulan y se distribuyen en forma de capital de distribución, lo que puede reducir la volatilidad de los ingresos.\n",
            "\n",
            "En los ETFs de distribución, los ingresos y los gastos se distribuyen a los accionistas en forma de dividendos mensuales o trimestrales. Esto significa que los accionistas pueden optar por reinvertir los dividendos en la ETF o retirirlos en forma de ingresos. Los ETFs de distribución pueden ser atractivos para los inversores que buscan un rendimiento más regular y predictible, ya que los dividendos se distribuyen con mayor frecuencia.\n",
            "\n",
            "En resumen, la principal diferencia entre ETFs de acumulación y ETFs de distribución es cómo se distribuyen los ingresos y los gastos entre los accionistas. Los ETFs de acumulación acumulan los ingresos y los gastos y se distribuyen en forma de capital de distribución, mientras que los ETFs de distribución distribuyen los ingresos y los gastos en forma de dividendos. El tipo de ETF que se elige depende de la estrategia de inversión y los objetivos de rendimiento del inversor.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"¿Cuál es la diferencia entre ETFs de acumulación y distribución?\"\n",
        "result = pipe(prompt)\n",
        "result_text = result[0]['generated_text']\n",
        "cleaned_text = result_text.split(\"<|assistant|>\")[-1].strip()\n",
        "print(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9knKZF-QEd",
        "outputId": "545b2b83-1667-4b53-94ef-55b28c013bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Cuales son las principales diferencias entre el MSCI World y el SP&500? \n",
            "\n",
            "Aunque ambos índices son medidas de rendimiento de la bolsa, hay algunas principales diferencias entre el MSCI World y el SP&500:\n",
            "\n",
            "1. Composición: El MSCI World es un índice global que mide el desempeño de las principales empresas de 23 países desarrollados y emergentes, mientras que el SP&500 se centra en las empresas más grandes y líderes de la economía estadounidense.\n",
            "\n",
            "2. Países: El MSCI World incluye empresas de países como Alemania, Japón, Reino Unido, Francia, China, Hong Kong, Taiwán, Sudáfrica, Australia, Nueva Zelanda, Singapur, Taiwán, Corea del Sur, y otros, además de los Estados Unidos. El SP&500 solo incluye empresas de los Estados Unidos.\n",
            "\n",
            "3. Sectorial: El MSCI World tiene una distribución sectorial más diversa que el SP&500, con una mayor representación de empresas de la industria tecnológica, de la salud y de la energía renovable. El SP&500 tiene una mayor representación de empresas de la industria de la tecnología de la información, de la finanzas y de la industria de la construcción.\n",
            "\n",
            "4. Pesos: El MSCI World tiene un peso más equilibrado entre las empresas de los diferentes países, mientras que el SP&500 tiene un peso más alto en las empresas estadounidenses.\n",
            "\n",
            "5. Calculación: El MSCI World utiliza un método de pesaje de capitalización de mercado, mientras que el SP&500 utiliza un método de pesaje de mercado libre.\n",
            "\n",
            "6. Frecuencia de rebalanzamiento: El MSCI World se rebalanza semestralmente, mientras que el SP&500 se rebalanza mensualmente.\n",
            "\n",
            "7. Fecha de lanzamiento: El MSCI World fue lanzado en 1986, mientras que el SP&500 fue lanzado en 1957.\n",
            "\n",
            "8. Administración: El MSCI World es administrado por MSCI, mientras que el SP&500 es administrado por S&P Dow Jones Indices.\n",
            "\n",
            "9. Tipo de empresa: El MSCI World incluye empresas de diferentes tipos de capitalización, incluyendo empresas de capitalización pequeña y mediana, mientras que el SP&500 solo incluye empresas de capitalización grande.\n",
            "\n",
            "10. Desempeño histórico: El MSCI World ha tenido un desempeño histórico más volátil que el SP&500, debido a la mayor diversificación de países y sectores. El SP&500 ha tenido un desempeño más estable, debido a la mayor concentración en empresas estadounidenses.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"¿Cuales son las principales diferencias entre el MSCI World y el SP&500?\"\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'].replace(\"<|assistant|>\", \"\").strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shhjnn6-DBFb",
        "outputId": "261eabf5-0632-4caf-fe2f-eacc42f22ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>: Eres un asistente financiero personal especializado en inversiones. Tu objetivo es ayudar a los usuarios con cualquier tema relacionado con inversiones, finanzas o economía. Para cada respuesta:\n",
            "1. Primero, busca los datos adecuados de tus conocimientos aprendidos o de las bases de datos externas disponibles.\n",
            "2. Luego, analiza cuidadosamente la consulta para dar una respuesta clara, precisa y personalizada.\n",
            "3. Mantente amable, profesional y enfocado únicamente en temas relacionados con inversiones, finanzas y economía.<|user|>: ¿En qué aspectos son diferentes UBS ETF - Factor MSCI EMU Low Volatility UCITS ETF (EUR) A-dis y Xtrackers Euro Stoxx 50 UCITS ETF 1C?<|assistant|>: \n",
            "<|assistant|>\n",
            "Las UBS ETF - Factor MSCI EMU Low Volatility UCITS ETF (EUR) A-dis y Xtrackers Euro Stoxx 50 UCITS ETF 1C son dos ETFs (Exchange Traded Funds) que se comercializan en Europa, pero presentan diferencias en sus objetivos de inversión.\n",
            "\n",
            "La UBS ETF - Factor MSCI EMU Low Volatility UCITS ETF (EUR) A-dis se centra en la baja volatilidad, lo que significa que selecciona aquellas acciones con un historial de volatilidad baja en el mercado de valores de la Unión Europea (UE). Este ETF busca reducir el riesgo de volatilidad para los inversores, lo que puede ser atractivo para aquellos que buscan un rendimiento más estable.\n",
            "\n",
            "En contraste, el Xtrackers Euro Stoxx 50 UCITS ETF 1C se centra en la composición del índice Euro Stoxx 50, que incluye las 50 principales empresas de la región económica de la UE. Este ETF ofrece una exposición directa a la economía de la UE y a las principales empresas de la región.\n",
            "\n",
            "En resumen, la UBS ETF - Factor MSCI EMU Low Volatility UCITS ETF (EUR) A-dis se centra en la baja volatilidad, mientras que el Xtrackers Euro Stoxx 50 UCITS ETF 1C se centra en la composición del índice Euro Stoxx 50. Los inversores deben evaluar sus objetivos de inversión y preferencias de riesgo para decidir cuál de estos ETFs es más adecuado para sus necesidades.\n"
          ]
        }
      ],
      "source": [
        "prompt = (\"<|system|>: Eres un asistente financiero personal especializado en inversiones. \"\n",
        "          \"Tu objetivo es ayudar a los usuarios con cualquier tema relacionado con inversiones, finanzas o economía. \"\n",
        "          \"Para cada respuesta:\\n\"\n",
        "          \"1. Primero, busca los datos adecuados de tus conocimientos aprendidos o de las bases de datos externas disponibles.\\n\"\n",
        "          \"2. Luego, analiza cuidadosamente la consulta para dar una respuesta clara, precisa y personalizada.\\n\"\n",
        "          \"3. Mantente amable, profesional y enfocado únicamente en temas relacionados con inversiones, finanzas y economía.\\n\"\n",
        "          \"<|user|>: ¿En qué aspectos son diferentes UBS ETF - Factor MSCI EMU Low Volatility UCITS ETF (EUR) A-dis y Xtrackers Euro Stoxx 50 UCITS ETF 1C?\"\n",
        "          \"<|assistant|>:\"\n",
        ")\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0yFxnM553Rh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "422833d6-44ec-4c72-b7e5-a6b1fc04bc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/ (stored 0%)\n",
            "updating: content/.config/ (stored 0%)\n",
            "updating: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "updating: content/.config/default_configs.db (deflated 98%)\n",
            "updating: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "updating: content/.config/gce (stored 0%)\n",
            "updating: content/.config/config_sentinel (stored 0%)\n",
            "updating: content/.config/.last_update_check.json (deflated 22%)\n",
            "updating: content/.config/logs/ (stored 0%)\n",
            "updating: content/.config/logs/2024.12.19/ (stored 0%)\n",
            "updating: content/.config/logs/2024.12.19/14.20.18.151587.log (deflated 58%)\n",
            "updating: content/.config/logs/2024.12.19/14.20.29.520330.log (deflated 57%)\n",
            "updating: content/.config/logs/2024.12.19/14.20.16.940511.log (deflated 87%)\n",
            "updating: content/.config/logs/2024.12.19/14.19.43.316528.log (deflated 93%)\n",
            "updating: content/.config/logs/2024.12.19/14.20.30.129972.log (deflated 57%)\n",
            "updating: content/.config/logs/2024.12.19/14.20.05.781718.log (deflated 58%)\n",
            "updating: content/.config/configurations/ (stored 0%)\n",
            "updating: content/.config/configurations/config_default (deflated 15%)\n",
            "updating: content/.config/active_config (stored 0%)\n",
            "updating: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "updating: content/TFG/ (stored 0%)\n",
            "updating: content/TFG/adapter_config.json (deflated 53%)\n",
            "updating: content/TFG/README.md (stored 0%)\n",
            "updating: content/TFG/adapter_model.safetensors (deflated 7%)\n",
            "updating: content/conceptos_inversiones_Q&A.jsonl (deflated 84%)\n",
            "updating: content/final_full_model/ (stored 0%)\n",
            "updating: content/final_full_model/tokenizer.json (deflated 85%)\n",
            "updating: content/final_full_model/generation_config.json (deflated 20%)\n",
            "updating: content/final_full_model/tokenizer_config.json (deflated 68%)\n",
            "updating: content/final_full_model/tokenizer.model (deflated 55%)\n",
            "updating: content/final_full_model/model.safetensors (deflated 18%)\n",
            "updating: content/final_full_model/special_tokens_map.json (deflated 70%)\n",
            "updating: content/final_full_model/config.json (deflated 54%)\n",
            "updating: content/recomendaciones_iniciales.jsonl (deflated 98%)\n",
            "updating: content/wandb/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/tmp/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/tmp/code/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/requirements.txt (deflated 55%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/wandb-summary.json (deflated 46%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/wandb-metadata.json (deflated 44%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/config.yaml (deflated 74%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/files/output.log (deflated 86%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/logs/ (stored 0%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/logs/debug-core.log (deflated 64%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/logs/debug-internal.log (deflated 74%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/logs/debug.log (deflated 68%)\n",
            "updating: content/wandb/run-20241221_142905-1fl7aonm/run-1fl7aonm.wandb (deflated 79%)\n",
            "updating: content/wandb/latest-run/ (stored 0%)\n",
            "updating: content/wandb/latest-run/tmp/ (stored 0%)\n",
            "updating: content/wandb/latest-run/tmp/code/ (stored 0%)\n",
            "updating: content/wandb/latest-run/files/ (stored 0%)\n",
            "updating: content/wandb/latest-run/files/requirements.txt (deflated 55%)\n",
            "updating: content/wandb/latest-run/files/wandb-summary.json (deflated 47%)\n",
            "updating: content/wandb/latest-run/files/wandb-metadata.json (deflated 44%)\n",
            "updating: content/wandb/latest-run/files/config.yaml (deflated 74%)\n",
            "updating: content/wandb/latest-run/files/output.log (deflated 86%)\n",
            "updating: content/wandb/latest-run/logs/ (stored 0%)\n",
            "updating: content/wandb/latest-run/logs/debug-core.log (deflated 64%)\n",
            "updating: content/wandb/latest-run/logs/debug-internal.log (deflated 74%)\n",
            "updating: content/wandb/latest-run/logs/debug.log (deflated 68%)\n",
            "updating: content/wandb/debug-internal.log (deflated 74%)\n",
            "updating: content/wandb/debug.log (deflated 68%)\n",
            "updating: content/q&a_comparaciones_esquematico.jsonl (deflated 93%)\n",
            "updating: content/results/ (stored 0%)\n",
            "updating: content/results/checkpoint-716/ (stored 0%)\n",
            "updating: content/results/checkpoint-716/adapter_config.json (deflated 53%)\n",
            "updating: content/results/checkpoint-716/tokenizer.json (deflated 85%)\n",
            "updating: content/results/checkpoint-716/scheduler.pt (deflated 56%)\n",
            "updating: content/results/checkpoint-716/trainer_state.json (deflated 77%)\n",
            "updating: content/results/checkpoint-716/optimizer.pt (deflated 8%)\n",
            "updating: content/results/checkpoint-716/README.md (deflated 66%)\n",
            "updating: content/results/checkpoint-716/tokenizer_config.json (deflated 68%)\n",
            "updating: content/results/checkpoint-716/tokenizer.model (deflated 55%)\n",
            "updating: content/results/checkpoint-716/training_args.bin (deflated 51%)\n",
            "updating: content/results/checkpoint-716/rng_state.pth (deflated 25%)\n",
            "updating: content/results/checkpoint-716/special_tokens_map.json (deflated 70%)\n",
            "updating: content/results/checkpoint-716/adapter_model.safetensors (deflated 7%)\n",
            "updating: content/results/checkpoint-500/ (stored 0%)\n",
            "updating: content/results/checkpoint-500/adapter_config.json (deflated 53%)\n",
            "updating: content/results/checkpoint-500/tokenizer.json (deflated 85%)\n",
            "updating: content/results/checkpoint-500/scheduler.pt (deflated 55%)\n",
            "updating: content/results/checkpoint-500/trainer_state.json (deflated 75%)\n",
            "updating: content/results/checkpoint-500/optimizer.pt (deflated 8%)\n",
            "updating: content/results/checkpoint-500/README.md (deflated 66%)\n",
            "updating: content/results/checkpoint-500/tokenizer_config.json (deflated 68%)\n",
            "updating: content/results/checkpoint-500/tokenizer.model (deflated 55%)\n",
            "updating: content/results/checkpoint-500/training_args.bin (deflated 51%)\n",
            "updating: content/results/checkpoint-500/rng_state.pth (deflated 25%)\n",
            "updating: content/results/checkpoint-500/special_tokens_map.json (deflated 70%)\n",
            "updating: content/results/checkpoint-500/adapter_model.safetensors (deflated 7%)\n",
            "updating: content/q&a_comparaciones_conversacionales.jsonl (deflated 93%)\n",
            "updating: content/sample_data/ (stored 0%)\n",
            "updating: content/sample_data/anscombe.json (deflated 83%)\n",
            "updating: content/sample_data/README.md (deflated 39%)\n",
            "updating: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "updating: content/sample_data/california_housing_train.csv (deflated 79%)\n",
            "updating: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "updating: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/wandb-metadata.json (deflated 44%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/config.yaml (deflated 72%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/files/output.log (deflated 39%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/logs/debug-core.log (deflated 66%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/logs/debug-internal.log (deflated 73%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/logs/debug.log (deflated 67%)\n",
            "  adding: content/wandb/run-20241221_152515-tt5m98wg/run-tt5m98wg.wandb (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/run-wa75hk1c.wandb (deflated 79%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/wandb-summary.json (deflated 47%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/wandb-metadata.json (deflated 44%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/config.yaml (deflated 74%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/files/output.log (deflated 86%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/logs/debug-core.log (deflated 64%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/logs/debug-internal.log (deflated 74%)\n",
            "  adding: content/wandb/run-20241221_153508-wa75hk1c/logs/debug.log (deflated 68%)\n",
            "  adding: content/wandb/latest-run/run-wa75hk1c.wandb (deflated 79%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4daeea16-fecb-461d-b9b2-ba44914ccdda\", \"file.zip\", 4242063356)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!zip -r /content/file.zip /content\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab60c7cea29d462aa75bb730ce11f750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb6ee71b97e642558f7f6903d335285b",
              "IPY_MODEL_21039639d149416db4741b3cd54b7f27",
              "IPY_MODEL_2d328342e6664f7ca0ef31420bce4911"
            ],
            "layout": "IPY_MODEL_f18a1bbb76b049c2a1aa3e02be684369"
          }
        },
        "eb6ee71b97e642558f7f6903d335285b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3709d0c8e4241f89b9f411cfbe350e0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e51d8a214ea4d9cac422c0b947042b0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "21039639d149416db4741b3cd54b7f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962dd6e798c74355a092724b971b73f2",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57a7b7dc6d4f49038c74b1ddf1050ee9",
            "value": 8
          }
        },
        "2d328342e6664f7ca0ef31420bce4911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c57afe3f6a642efa2ac25487f94501f",
            "placeholder": "​",
            "style": "IPY_MODEL_02d84bf01bd84b299cca24b1c7b5dc41",
            "value": " 8/8 [00:06&lt;00:00,  1.28it/s]"
          }
        },
        "f18a1bbb76b049c2a1aa3e02be684369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3709d0c8e4241f89b9f411cfbe350e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e51d8a214ea4d9cac422c0b947042b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "962dd6e798c74355a092724b971b73f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a7b7dc6d4f49038c74b1ddf1050ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c57afe3f6a642efa2ac25487f94501f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d84bf01bd84b299cca24b1c7b5dc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "344c0d5411604acdb9c97b06efb0ffae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b9d9c3a8b84ae29032f8245041fdb6",
              "IPY_MODEL_8247dada9c4a46b59dc7da9a34ef2261",
              "IPY_MODEL_c97eccca84d941648870bc0e4044e7da"
            ],
            "layout": "IPY_MODEL_bc3917063ce9468aa4adc34f5f0a02fd"
          }
        },
        "b3b9d9c3a8b84ae29032f8245041fdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71b86daf3c640588fdb0e05a789cab7",
            "placeholder": "​",
            "style": "IPY_MODEL_fd556626f812485e9b986236bc303e0f",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "8247dada9c4a46b59dc7da9a34ef2261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f015bc8e46343f3ab99878210048b18",
            "max": 27280152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f91942b04ef2457989c583ee99bccdea",
            "value": 27280152
          }
        },
        "c97eccca84d941648870bc0e4044e7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853aa6e74e5a491c8b7d612c100ec88d",
            "placeholder": "​",
            "style": "IPY_MODEL_412eba01a7fd406b9b42247fbd2cde40",
            "value": " 27.3M/27.3M [00:04&lt;00:00, 14.9MB/s]"
          }
        },
        "bc3917063ce9468aa4adc34f5f0a02fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71b86daf3c640588fdb0e05a789cab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd556626f812485e9b986236bc303e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f015bc8e46343f3ab99878210048b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91942b04ef2457989c583ee99bccdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "853aa6e74e5a491c8b7d612c100ec88d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412eba01a7fd406b9b42247fbd2cde40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}